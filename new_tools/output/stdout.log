Preparing data...
Data prepared.

Loading model...
Base model architecture:
MLPmodel(
  (bn_1): BatchNorm1d(27, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (dense_1): Linear(in_features=27, out_features=64, bias=True)
  (dense_2): Linear(in_features=64, out_features=32, bias=True)
  (dense_3): Linear(in_features=32, out_features=32, bias=True)
  (output): Linear(in_features=32, out_features=2, bias=True)
)
Model loaded.

Training and optimizing model...
Epoch 1/100, Train Loss: 0.2289, Val Loss: 0.2433
Epoch 2/100, Train Loss: 0.2508, Val Loss: 0.2303
Epoch 3/100, Train Loss: 0.2601, Val Loss: 0.2281
Epoch 4/100, Train Loss: 0.2271, Val Loss: 0.2233
Epoch 5/100, Train Loss: 0.2570, Val Loss: 0.2222
Epoch 6/100, Train Loss: 0.2237, Val Loss: 0.2209
Epoch 7/100, Train Loss: 0.2229, Val Loss: 0.2206
Epoch 8/100, Train Loss: 0.2285, Val Loss: 0.2190
Epoch 9/100, Train Loss: 0.1839, Val Loss: 0.2171
Epoch 10/100, Train Loss: 0.1896, Val Loss: 0.2175
Epoch 11/100, Train Loss: 0.2448, Val Loss: 0.2182
Epoch 12/100, Train Loss: 0.2056, Val Loss: 0.2192
Epoch 13/100, Train Loss: 0.2316, Val Loss: 0.2157
Epoch 14/100, Train Loss: 0.2283, Val Loss: 0.2161
Epoch 15/100, Train Loss: 0.2170, Val Loss: 0.2157
Epoch 16/100, Train Loss: 0.1968, Val Loss: 0.2147
Epoch 17/100, Train Loss: 0.2019, Val Loss: 0.2139
Epoch 18/100, Train Loss: 0.2373, Val Loss: 0.2161
Epoch 19/100, Train Loss: 0.2420, Val Loss: 0.2138
Epoch 20/100, Train Loss: 0.2218, Val Loss: 0.2170
Epoch 21/100, Train Loss: 0.2491, Val Loss: 0.2137
Epoch 22/100, Train Loss: 0.2390, Val Loss: 0.2141
Epoch 23/100, Train Loss: 0.2177, Val Loss: 0.2146
Epoch 24/100, Train Loss: 0.1883, Val Loss: 0.2139
Epoch 25/100, Train Loss: 0.2018, Val Loss: 0.2136
Epoch 26/100, Train Loss: 0.1824, Val Loss: 0.2117
Epoch 27/100, Train Loss: 0.2365, Val Loss: 0.2122
Epoch 28/100, Train Loss: 0.2314, Val Loss: 0.2122
Epoch 29/100, Train Loss: 0.2185, Val Loss: 0.2133
Epoch 30/100, Train Loss: 0.2109, Val Loss: 0.2118
Epoch 31/100, Train Loss: 0.2113, Val Loss: 0.2167
Epoch 32/100, Train Loss: 0.2302, Val Loss: 0.2122
Epoch 33/100, Train Loss: 0.2254, Val Loss: 0.2131
Epoch 34/100, Train Loss: 0.2348, Val Loss: 0.2126
Epoch 35/100, Train Loss: 0.2599, Val Loss: 0.2140
Epoch 36/100, Train Loss: 0.2303, Val Loss: 0.2110
Epoch 37/100, Train Loss: 0.2386, Val Loss: 0.2120
Epoch 38/100, Train Loss: 0.2476, Val Loss: 0.2113
Epoch 39/100, Train Loss: 0.1743, Val Loss: 0.2116
Epoch 40/100, Train Loss: 0.1989, Val Loss: 0.2117
Epoch 41/100, Train Loss: 0.2096, Val Loss: 0.2117
Epoch 42/100, Train Loss: 0.2331, Val Loss: 0.2117
Epoch 43/100, Train Loss: 0.2284, Val Loss: 0.2121
Epoch 44/100, Train Loss: 0.2207, Val Loss: 0.2107
Epoch 45/100, Train Loss: 0.1972, Val Loss: 0.2108
Epoch 46/100, Train Loss: 0.2666, Val Loss: 0.2114
Epoch 47/100, Train Loss: 0.2211, Val Loss: 0.2138
Epoch 48/100, Train Loss: 0.2280, Val Loss: 0.2114
Epoch 49/100, Train Loss: 0.2325, Val Loss: 0.2123
Epoch 50/100, Train Loss: 0.2060, Val Loss: 0.2123
Epoch 51/100, Train Loss: 0.2091, Val Loss: 0.2107
Epoch 52/100, Train Loss: 0.2155, Val Loss: 0.2122
Epoch 53/100, Train Loss: 0.2488, Val Loss: 0.2119
Epoch 54/100, Train Loss: 0.2101, Val Loss: 0.2134
Epoch 55/100, Train Loss: 0.1957, Val Loss: 0.2102
Epoch 56/100, Train Loss: 0.2364, Val Loss: 0.2121
Epoch 57/100, Train Loss: 0.2357, Val Loss: 0.2141
Epoch 58/100, Train Loss: 0.2114, Val Loss: 0.2130
Epoch 59/100, Train Loss: 0.2244, Val Loss: 0.2116
Epoch 60/100, Train Loss: 0.1975, Val Loss: 0.2116
Epoch 61/100, Train Loss: 0.2006, Val Loss: 0.2115
Epoch 62/100, Train Loss: 0.2280, Val Loss: 0.2123
Epoch 63/100, Train Loss: 0.2011, Val Loss: 0.2113
Epoch 64/100, Train Loss: 0.2520, Val Loss: 0.2109
Epoch 65/100, Train Loss: 0.2378, Val Loss: 0.2125
Early stopping: Validation loss did not improve for 10 epochs
Training and optimization completed.

testing model...
Testing completed

